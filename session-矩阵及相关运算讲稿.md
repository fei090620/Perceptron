
# 线性代数（向量，矩阵及相关运算）

## 开场白
在开聊之前，我有几个对大家的假设：
> 首先，假设你第一次接触线性代数，或者对于矩阵，向量，特征值等概念只是存在模糊的印象；

> 其次，假设你学习线性代数的目标是理解机器学习相关算法的原理；

> 最后，假设你依然保留了学习数学的热情；

当然，这三个假设对于我们所有人并不是都成立，所以我们有一些弹性措施，同时也是为了节省大家的时间，如果你对第一条假设不成立，嗯，请拖动视频至10分钟以后开始；如果是第二条，实在抱歉，可能这次的分享不太适合你，你可以找我，我们可以聊点其他的有关线性代数的话题；最后如果你已经对数学热情不再，非常荣幸，这次分享就是为你准备的。好，我们开始。

我们从三个梯度来讲述线性代数：

1. 概念

   概念的目的是解决“是什么？”也就是What?的问题，用来和其他的东西进行区分，而我们今天要聊的概念有“向量”，“矩阵及运算”，“线性空间”，“特征值与特征向量”，他们之间存在一个关系图，如下图：
   
   向量 --> 矩阵及运算 --> 线性空间 --> 特征值与特征向量 

   其中，向量是最基础的，其次是矩阵及其运算，再然后是线性空间，最后是特征值与特征向量，这里是根据知识点的依赖关系来描述。

   1. 向量

   向量其实是一种数据结构。一般我们这么定义一个向量a = (1,0),其中1和0分别表示a向量的终点在平面坐标系中的坐标，这是描述性定义，在坐标系中，向量的表示就是一条从原点出发指向点（1，0）的有向线段，因为是线段所有有长度，所以方向和长度是向量的两个核心要素。当然，平面坐标系是二维的，所以我们可以描述二维向量，如果是三维空间坐标系，自然可以描述三维向量，比如b = (1,0,0),那么更高维度的，拓展开就需要更高维度的坐标系，这里很难用图示的形式展示，不过从逻辑上很好理解，我们定义一个n维的向量a(n) = (x1,x2,...,xn)

   `` 向量内积 `` ：


   2. 矩阵

   矩阵也可以理解为一种数据结构，直观来看有行和列，像个九宫格，当然不一定是3行3列，可以是n行m列，其中n,m都是正整数，直观的看，矩阵就是这样的。但是，从线性空间的角度来看，矩阵其实代表这线性空间中向量的线性变换，当然，这是后话。

   那么，矩阵有那些运算呢？
   
   `` 数乘 `` ：矩阵可以做数乘，也就是A*b，其中A是矩阵，b是个实数，这里我们缩小了b的范围，更大范围的描述对于我们理解其实意义不大，一个矩阵和一个数相乘等于矩阵中每个元素和这个数相乘，结果是一个和A的行和列都一样的新矩阵；


   `` 矩阵乘法 `` ：A*B两个矩阵做乘法，其中A是n行m列，B是m行l列,那么相乘的结果就是n行l列的新矩阵，具体的计算过程是这样的，A的第i行和B的第j列做内积，

   3. 线性空间

   

   `` 行列式 `` :

   `` 矩阵分解 `` ：

    






2. 使用


3. 性质
